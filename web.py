import streamlit as st
import cv2
import numpy as np
import tensorflow as tf
from PIL import Image
import time

st.set_page_config(page_title="Autonomous Road AI", layout="wide")

st.markdown("""
    <style>
    .stMetric { background-color: #1e2130; padding: 15px; border-radius: 10px; border: 1px solid #00ff80; }
    h1, h2 { color: #00ff80; }
    </style>
    """, unsafe_allow_html=True)

@st.cache_resource
def load_model():
    return tf.keras.models.load_model('tesla_road_model.keras')

model = load_model()
IMG_SIZE = 256

@tf.function
def fast_predict(input_data):
    return model(input_data, training=False)


with st.sidebar:
    st.header("âš™ï¸ System Specs")
    st.markdown("---")
    st.write("**Architecture:** U-Net CNN")
    st.write("**Input Size:** 256x256 RGB")
    st.write("**Framework:** TensorFlow 2.15")
    st.write("**Backend:** Apple Silicon Metal")
    st.markdown("---")
    st.success("System Status: Online")


st.title("ðŸŽï¸ Autonomous Vision Control Center")


m1, m2, m3 = st.columns(3)
m1.metric("Model Accuracy", "94.2%", "CamVid Standard")
m2.metric("Inference Time", "0.86ms", "Ultra-Low Latency")
m3.metric("Peak Performance", "1100+ FPS", "Real-Time")

st.divider()


tab1, tab2, tab3, tab4 = st.tabs(["ðŸ–¼ï¸ Image", "ðŸ“¹ Video File", "ðŸŽ¥ Live Stream", "ðŸ—ï¸ Architecture"])


with tab1:
    uploaded_img = st.file_uploader("Upload Scene", type=['png', 'jpg', 'jpeg'], key="img")
    if uploaded_img:
        col1, col2 = st.columns(2)
        img = Image.open(uploaded_img)
        img_np = np.array(img)
        

        input_t = tf.convert_to_tensor(np.expand_dims(cv2.resize(img_np, (IMG_SIZE, IMG_SIZE)) / 255.0, axis=0).astype(np.float32))
        start = time.perf_counter()
        pred = fast_predict(input_t)
        inf_ms = (time.perf_counter() - start) * 1000
        
        # Overlay
        mask = (pred.numpy()[0] > 0.5).astype(np.uint8)
        mask_res = cv2.resize(mask, (img_np.shape[1], img_np.shape[0]))
        res_img = img_np.copy()
        res_img[mask_res == 1] = [0, 255, 128]
        
        col1.image(img_np, caption="Original View")
        col2.image(res_img, caption=f"AI Segmentation Map ({inf_ms:.2f} ms)")


with tab2:
    up_vid = st.file_uploader("Upload Video", type=['mp4', 'mov'], key="vid")
    if up_vid:
        with open("temp.mp4", "wb") as f: f.write(up_vid.read())
        cap = cv2.VideoCapture("temp.mp4")
        st_vid = st.empty()
        if st.button("Run Video Analysis"):
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret: break
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                inp = tf.convert_to_tensor(np.expand_dims(cv2.resize(frame_rgb, (IMG_SIZE, IMG_SIZE)) / 255.0, axis=0).astype(np.float32))
                pred = fast_predict(inp)
                mask = (pred.numpy()[0] > 0.5).astype(np.uint8)
                mask_res = cv2.resize(mask, (frame.shape[1], frame.shape[0]))
                frame_rgb[mask_res == 1] = [0, 255, 128]
                st_vid.image(frame_rgb, use_container_width=True)
            cap.release()


with tab3:
    run_live = st.toggle("Enable Local Camera Analysis")
    st_live = st.empty()
    if run_live:
        cam = cv2.VideoCapture(0)
        while run_live:
            ret, frame = cam.read()
            if not ret: break
            st_live.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), use_container_width=True)
        cam.release()


with tab4:
    st.subheader("System Pipeline")
    st.write("The model follows a classic U-Net architecture for pixel-wise classification.")
    
    st.markdown("""
    1. **Input:** RGB Frame ($256 \times 256 \times 3$)
    2. **Encoder:** Feature extraction via Convolutional layers.
    3. **Decoder:** Upsampling to original spatial resolution.
    4. **Output:** Probability map for road surface.
    """)